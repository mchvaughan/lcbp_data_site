depth_in = Depth) %>%
mutate(year = date %>% year(),
month = date %>% month(),
week = date %>% week(),
fake_year = case_when(
month >= 9 ~ date %>% update(year = 1990),
month < 9 ~ date %>% update(year = 1991)),
julian_day = date %>% yday(),
winter_day = julian_day - 250,
winter = case_when(
month >= 9 ~ paste0(year, "-", (year + 1)),
month < 9 ~ paste0((year - 1), "-", year))) %>%
filter(month >= 9 | month < 7) %>%
drop_na(depth_in) %>%
group_by(fake_year) %>%
nest() %>%
mutate(new = map(.x = data, .f = ~.x %>% #find percentile of each depth based on date
mutate(daily_percent_rank = depth_in %>% percent_rank()))) %>%
select(-data) %>%
unnest(new) %>%
mutate(percentile_label = (daily_percent_rank * 100) %>%
round(digits = 1) %>%
paste0("Percentile: ", .))
this_year <- snow %>%
filter(winter == this_winter)
latest_date <- snow %>%
pull("date") %>%
max()
latest_depth <- snow %>%
filter(date == latest_date) %>%
pluck("depth_in", 1)
latest_percentile <- snow %>%
filter(date == latest_date) %>%
pluck("daily_percent_rank", 1) %>%
prod(100) %>% # multiply by 100 to get %
round(digits = 1)
# write it
snow %>%
write_csv("plotdata/snow.csv")
# Imagery -------------------------------
# link making function
image_link <- function(date){
year <- year(date)
month <- month(date)
day <- day(date)
yday <- yday(date)
year_last2 <- year %>%
as.character() %>%
str_trunc(2, "left", ellipsis = "")
if (month < 10){month <- paste0("0", month)} # add a leading zero if less than 100
if (day < 10){day <- paste0("0", day)} # add a leading zero if less than 10
if (yday < 10){
yday <- paste0("00", yday) # add two leading zeros if less than 10
} else if (yday < 100){
yday <- paste0("0", yday)} # add a leading zero if less than 100
link <-
"https://ge.ssec.wisc.edu/modis-today/images/terra/true_color/" %>%
paste0(year,
"_",
month,
"_",
day,
"_",
yday,
"/t1.",
year_last2,
yday,
".USA4.143.250m.jpg"
)
return(link)
}
# create image for yesterday
(Sys.Date() - 1) %>%
image_link() %>%
image_read() %>% # read in image from url
image_crop("900x1200+2250+2150") %>%
image_write("plotdata/sat_yesterday.png", format = "png")
# function to make gif for past week
gif_maker2 <- function(days_before){ # same as before, but just enter how many days you want to go back before yesterday
yesterday <- Sys.Date() - 1
date_list <-
seq((yesterday - days_before), yesterday, 1) %>%
as.character() # to character
gif <- date_list %>%
tibble(dates = .) %>%
mutate(links = map_chr(.x = dates, .f = ~.x %>% # create links using function above
image_link())) %>%
pull("links") %>%
image_read() %>% # read in image from url
image_crop("900x1200+2250+2150") %>% # crop to Lake Champlain
image_annotate(date_list,
size = 70,
gravity = "SouthEast",
boxcolor = "grey85",
color = "black") %>%
image_animate(optimize = TRUE, # create animation from images
fps = 0.5)
return(gif)
}
gif_maker2(7) %>%
image_write("plotdata/sat_week.gif",
format = "gif")
# Load packages
library(rmarkdown)
# first run code to process new data
"lcbp_data_processor.r" %>%
source()
library(tidyverse)
"lcbp_data_processor.r" %>%
source()
Sys.sleep(30)
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
library(tidyverse)
library(plotly)
library(lubridate)
library(viridis)
library(scales)
library(mapboxapi)
library(leaflet)
knitr::opts_chunk$set(echo = FALSE)
this_hour <- Sys.time() %>% # find the current hour, for caching
hour()
lake_level_together <- "plotdata/lake_level.csv" %>%
read_csv() %>%
mutate(station = station %>%
fct_reorder2(timestamp, elevation_ft)) %>%
ggplot() +
geom_line(aes(x = timestamp,
y = elevation_ft,
color = station),
size = 1,
alpha = 0.5) +
scale_color_viridis("Level station",
discrete = TRUE) +
scale_y_continuous(breaks = pretty_breaks()) +
scale_x_datetime(breaks = pretty_breaks()) +
labs(x = "",
y = "Lake water surface elevation\n(feet above NGVD 1929)") +
theme(axis.text = element_text(face = "bold",
size = 14),
axis.title = element_text(face = "bold",
size = 14),
legend.text = element_text(face = "bold",
size = 10))
ggplotly(lake_level_together)
# plot water temps in deg F
lake_temp_together_degF <- "plotdata/lake_temp.csv" %>%
read_csv() %>%
mutate(station = station %>%
fct_reorder2(timestamp, water_temp_degF)) %>%
ggplot() +
geom_line(aes(x = timestamp,
y = water_temp_degF,
color = station),
size = 1,
alpha = 0.5) +
scale_color_viridis("Temperature station",
discrete = TRUE) +
scale_y_continuous(breaks = pretty_breaks()) +
scale_x_datetime(breaks = pretty_breaks()) +
labs(x = "",
y = "Lake water temperature\n(Degrees F)") +
theme(axis.text = element_text(face = "bold",
size = 14),
axis.title = element_text(face = "bold",
size = 14),
legend.text = element_text(face = "bold",
size = 10))
ggplotly(lake_temp_together_degF)
tribq <- "plotdata/tribq.csv" %>%
read_csv()
tribq_together_cfs <- tribq %>%
mutate(trib = trib %>%
fct_reorder2(timestamp, discharge_cms)) %>%
ggplot() +
geom_line(aes(x = timestamp,
y = discharge_cfs,
color = trib),
size = 1,
alpha = 0.5) +
scale_color_viridis("Tributary",
discrete = TRUE) +
labs(x = "",
y = "Discharge (cubic feet per second)") +
theme(axis.text = element_text(face = "bold",
size = 14),
axis.title = element_text(face = "bold",
size = 14),
legend.text = element_text(face = "bold",
size = 10))
ggplotly(tribq_together_cfs)
# Sum discharges together by timestamp
combined_q <- tribq %>%
select(!c(trib, gage_number)) %>%
group_by(timestamp) %>%
summarise(total_discharge_cms = sum(discharge_cms),
total_discharge_cfs = sum(discharge_cfs),
n = n()) %>%
filter(!n < max(n)) # remove timestamps that don't include all tribs
combined_q_plot_cfs <- combined_q %>%
ggplot() +
geom_line(aes(x = timestamp, y = total_discharge_cfs)) +
labs(x = "",
y = paste("Total measured discharge\n(cubic feet per second)")) +
theme(axis.text = element_text(face = "bold",
size = 14),
axis.title = element_text(face = "bold",
size = 12),
legend.text = element_text(face = "bold",
size = 10))
n_combined_tribs <- combined_q %>%
pull("n") %>%
max()
ggplotly(combined_q_plot_cfs)
# define buoy location
station_loc <- "data/trib_station_info.csv" %>%
read_csv()
# subbasins_poly <- "data/lcb_subbasin_shapefile/LCB_2013_subbasins.shp" %>%
#                   st_read()
# create the map
station_loc %>%
leaflet() %>%
addProviderTiles("Esri.WorldImagery") %>%
# addPolygons(data = subbasins_poly) %>%
addMarkers(lng = ~lng,
lat = ~lat,
label = ~trib)
lamoille_plot <- "plotdata/lamoille.csv" %>%
read_csv() %>%
select(-c(pH_mV, odo_mgL, cond_uScm, pH)) %>%
pivot_longer(-timestamp,
names_to = "var",
values_to = "value") %>%
mutate(var = var %>%
recode(odo_pct_sat = "Dissolved oxygen (percent saturation)",
sp_cond_uScm = "Specific conductivity (uS/cm)",
temp_degC = "Temperature (degrees Celsius)",
turb_fnu = "Turbidity (FNU)",
nitrate_mgL = "Nitrate-N (mg/L)")) %>%
ggplot() +
geom_line(aes(x = timestamp,
y = value,
color = var)) +
facet_wrap(var ~ .,
scales = "free_y",
ncol = 1,
strip.position = "left") +
scale_color_viridis(discrete = TRUE) +
theme(legend.position = "none",
text = element_text(face = "bold",
size = 14)) +
labs(x = "", y = "")
lamoille_plot
?ggplotly
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Setup ---------------------------------------
library(tidyverse)
library(lubridate)
library(dataRetrieval)
library(weathermetrics)
library(RCurl)
library(magick)
ftp_info <- "data/ftp_info.csv" %>%
read_csv()
valcour_url <- ftp_info %>%
pluck("address", 1)
ftp_credentials <- ftp_info %>%
pluck("credentials", 1)
trib_station_info <- "data/trib_station_info.csv" %>%
read_csv() %>%
mutate(gage_number = gage_number %>% # Add leading zero to all gage codes
paste0("0", .))
trib_day_window <- 30
param_code <- "00060" # discharge in cfs
time_zone <- "America/New_York"
end <- Sys.Date()
start <-  end - duration(trib_day_window, units = "days")
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
View(tribq)
library(rmarkdown)
library(tidyverse)
# first run code to process new data
"lcbp_data_processor.r" %>%
source()
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
# Render the RMarkdown file
"lcbp_data_site.Rmd" %>%
render(output_file = "index.html")
tribq <- "plotdata/tribq.csv" %>%
read_csv()
View(tribq)
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
View(tribq)
getwd()
tribq <- "plotdata/tribq.csv" %>%
read_csv()
?read_csv
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms))))
View(tribq)
View(tribq[[3]][[12]])
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
tribq %>%
write_csv("plotdata/tribq.csv")
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168,
timestamp = timestamp %>%
as_date()) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms))))
View(tribq[[3]][[4]])
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168,
timestamp = timestamp %>%
as_datetime()) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms))))
View(tribq[[3]][[6]])
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168,
timestamp = timestamp %>%
as_datetime()) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
# write it
tribq %>%
write_csv("plotdata/tribq.csv")
# write it
tribq %>%
write_csv("plotdata/tribq.csv")
tribq2 <- "plotdata/tribq.csv" %>%
read_csv()
View(tribq2)
View(tribq)
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168,
timestamp = timestamp %>%
as_datetime()) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
View(tribq)
?as_datetime
Sys.timezone
Sys.timezone()
tribq <- trib_station_info %>%
select(c(trib, gage_number)) %>%
mutate(qdata = map(.x = gage_number,
.f = ~readNWISuv(siteNumber = .x,
startDate = start,
endDate = end,
parameterCd = param_code,
tz = time_zone) %>%
rename(timestamp = dateTime,
discharge_cfs = X_00060_00000) %>%
mutate(discharge_cms = discharge_cfs * 0.0283168,
timestamp = timestamp %>%
as_datetime(tz = "America/New_York")) %>%
select(c(timestamp,
discharge_cfs,
discharge_cms)))) %>%
unnest(qdata)
View(tribq)
tribq2 <- "plotdata/tribq.csv" %>%
read_csv()
tribq_together_cfs <- tribq %>%
mutate(trib = trib %>%
fct_reorder2(timestamp, discharge_cms)) %>%
ggplot() +
geom_line(aes(x = timestamp,
y = discharge_cfs,
color = trib),
size = 1,
alpha = 0.5) +
scale_color_viridis("Tributary",
discrete = TRUE) +
labs(x = "",
y = "Discharge (cubic feet per second)") +
theme(axis.text = element_text(face = "bold",
size = 14),
axis.title = element_text(face = "bold",
size = 14),
legend.text = element_text(face = "bold",
size = 10))
ggplotly(tribq_together_cfs)
View(tribq2)
tribq2 <- "plotdata/tribq.csv" %>%
read_csv()
# write it
tribq %>%
write_csv("plotdata/tribq.csv")
tribq2 <- "plotdata/tribq.csv" %>%
read_csv()
View(tribq2)
View(tribq)
View(tribq2)
